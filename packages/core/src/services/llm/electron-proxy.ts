import { ILLMService, Message, StreamHandlers, LLMResponse, ModelOption, ToolDefinition } from './types';
import { safeSerializeForIPC } from '../../utils/ipc-serialization';

/**
 * Electronç¯å¢ƒä¸‹çš„LLMæœåŠ¡ä»£ç†
 * é€šè¿‡IPCè°ƒç”¨ä¸»è¿›ç¨‹ä¸­çš„çœŸå®LLMServiceå®ä¾‹
 */
export class ElectronLLMProxy implements ILLMService {
  private electronAPI: NonNullable<Window['electronAPI']>;

  constructor() {
    // éªŒè¯Electronç¯å¢ƒ
    if (typeof window === 'undefined' || !window.electronAPI) {
      throw new Error('ElectronLLMProxy can only be used in Electron renderer process');
    }
    this.electronAPI = window.electronAPI;
  }

  async testConnection(provider: string): Promise<void> {
    await this.electronAPI.llm.testConnection(provider);
  }

  async sendMessage(messages: Message[], provider: string): Promise<string> {
    // è‡ªåŠ¨åºåˆ—åŒ–ï¼Œé˜²æ­¢Vueå“åº”å¼å¯¹è±¡IPCä¼ é€’é”™è¯¯
    const safeMessages = safeSerializeForIPC(messages);
    return this.electronAPI.llm.sendMessage(safeMessages, provider);
  }

  async sendMessageStructured(messages: Message[], provider: string): Promise<LLMResponse> {
    // è‡ªåŠ¨åºåˆ—åŒ–ï¼Œé˜²æ­¢Vueå“åº”å¼å¯¹è±¡IPCä¼ é€’é”™è¯¯
    const safeMessages = safeSerializeForIPC(messages);
    return this.electronAPI.llm.sendMessageStructured(safeMessages, provider);
  }

  async sendMessageStream(
    messages: Message[],
    provider: string,
    callbacks: StreamHandlers
  ): Promise<void> {
    // è‡ªåŠ¨åºåˆ—åŒ–ï¼Œé˜²æ­¢Vueå“åº”å¼å¯¹è±¡IPCä¼ é€’é”™è¯¯
    const safeMessages = safeSerializeForIPC(messages);

    // é€‚é…å›è°ƒæ¥å£ï¼šStreamHandlers ä½¿ç”¨ onTokenï¼Œè€Œ preload æœŸæœ›çš„æ˜¯ onContent
    const adaptedCallbacks = {
      onContent: callbacks.onToken,  // æ˜ å°„ onToken -> onContent
      onThinking: callbacks.onReasoningToken || (() => {}),  // æ˜ å°„æ¨ç†æµ
      onFinish: () => callbacks.onComplete(),  // æ˜ å°„å®Œæˆå›è°ƒ
      onError: callbacks.onError
    };

    await this.electronAPI.llm.sendMessageStream(safeMessages, provider, adaptedCallbacks);
  }

  async sendMessageStreamWithTools(
    messages: Message[],
    provider: string,
    _tools: ToolDefinition[], // ä½¿ç”¨ä¸‹åˆ’çº¿å‰ç¼€è¡¨ç¤ºæš‚æ—¶æœªä½¿ç”¨
    callbacks: StreamHandlers
  ): Promise<void> {
    // è‡ªåŠ¨åºåˆ—åŒ–ï¼Œé˜²æ­¢Vueå“åº”å¼å¯¹è±¡IPCä¼ é€’é”™è¯¯
    const safeMessages = safeSerializeForIPC(messages);
    // const safeTools = safeSerializeForIPC(tools); // æš‚æ—¶ä¸ä½¿ç”¨ï¼Œç­‰å®ç°æ—¶å†å¯ç”¨

    // é€‚é…å›è°ƒæ¥å£ï¼šStreamHandlers ä½¿ç”¨ onToken/onToolCallï¼Œè€Œ preload æœŸæœ›ç›¸åº”çš„å›è°ƒ
    const adaptedCallbacks = {
      onContent: callbacks.onToken,  // æ˜ å°„ onToken -> onContent
      onThinking: callbacks.onReasoningToken || (() => {}),  // æ˜ å°„æ¨ç†æµ
      onToolCall: callbacks.onToolCall || (() => {}),  // ğŸ†• æ˜ å°„å·¥å…·è°ƒç”¨å›è°ƒ
      onFinish: () => callbacks.onComplete(),  // æ˜ å°„å®Œæˆå›è°ƒ
      onError: callbacks.onError
    };

    // TODO: éœ€è¦åœ¨ä¸»è¿›ç¨‹å’Œpreloadä¸­å®ç° sendMessageStreamWithTools æ–¹æ³•
    // æš‚æ—¶å›é€€åˆ°æ™®é€šæµå¼æ–¹æ³•
    console.warn('[ElectronLLMProxy] sendMessageStreamWithTools not yet implemented in main process, falling back to regular stream');
    await this.electronAPI.llm.sendMessageStream(safeMessages, provider, adaptedCallbacks);
  }

  async fetchModelList(
    provider: string,
    customConfig?: Partial<any>
  ): Promise<ModelOption[]> {
    // è‡ªåŠ¨åºåˆ—åŒ–ï¼Œé˜²æ­¢Vueå“åº”å¼å¯¹è±¡IPCä¼ é€’é”™è¯¯
    const safeCustomConfig = customConfig ? safeSerializeForIPC(customConfig) : customConfig;
    return this.electronAPI.llm.fetchModelList(provider, safeCustomConfig);
  }
} 