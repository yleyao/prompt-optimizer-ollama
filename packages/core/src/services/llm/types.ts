import { ModelConfig } from '../model/types';

/**
 * å·¥å…·è°ƒç”¨ç›¸å…³ç±»å‹
 */
export interface ToolCall {
  id: string;
  type: 'function';
  function: {
    name: string;
    arguments: string;
  };
}

export interface FunctionDefinition {
  name: string;
  description?: string;
  parameters?: object;
}

export interface ToolDefinition {
  type: 'function';
  function: FunctionDefinition;
}
/**
 * æ¶ˆæ¯è§’è‰²ç±»å‹
 */
export type MessageRole = 'system' | 'user' | 'assistant';

/**
 * æ¶ˆæ¯ç±»å‹
 */
export interface Message {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

/**
 * LLMå“åº”ç»“æ„
 */
export interface LLMResponse {
  content: string;
  reasoning?: string;
  toolCalls?: ToolCall[];  // ğŸ†• å·¥å…·è°ƒç”¨ä¿¡æ¯
  metadata?: {
    model?: string;
    tokens?: number;
    finishReason?: string;
  };
}

/**
 * æµå¼å“åº”å¤„ç†å™¨
 * æ”¯æŒä¼ ç»Ÿæ ¼å¼å’Œç»“æ„åŒ–æ ¼å¼
 */
export interface StreamHandlers {
  // ä¸»è¦å†…å®¹æµï¼ˆå¿…éœ€ï¼Œå‘åå…¼å®¹ï¼‰
  onToken: (token: string) => void;
  
  // æ¨ç†å†…å®¹æµï¼ˆå¯é€‰ï¼Œæ–°å¢åŠŸèƒ½ï¼‰
  onReasoningToken?: (token: string) => void;
  
  // å·¥å…·è°ƒç”¨å¤„ç†ï¼ˆğŸ†• æ–°å¢åŠŸèƒ½ï¼‰
  onToolCall?: (toolCall: ToolCall) => void;
  
  // å®Œæˆå›è°ƒï¼ˆç°åœ¨ä¼ é€’å®Œæ•´å“åº”ï¼Œå‘åå…¼å®¹é€šè¿‡å¯é€‰å‚æ•°ï¼‰
  onComplete: (response?: LLMResponse) => void;
  
  // é”™è¯¯å›è°ƒ
  onError: (error: Error) => void;
}

/**
 * æ¨¡å‹ä¿¡æ¯æ¥å£
 */
export interface ModelInfo {
  id: string;  // æ¨¡å‹IDï¼Œç”¨äºAPIè°ƒç”¨
  name: string; // æ˜¾ç¤ºåç§°
}

/**
 * ç”¨äºä¸‹æ‹‰é€‰æ‹©ç»„ä»¶çš„æ¨¡å‹é€‰é¡¹æ ¼å¼
 */
export interface ModelOption {
  value: string; // é€‰é¡¹å€¼ï¼Œé€šå¸¸æ˜¯æ¨¡å‹ID
  label: string; // æ˜¾ç¤ºæ ‡ç­¾ï¼Œé€šå¸¸æ˜¯æ¨¡å‹åç§°
}

/**
 * LLMæœåŠ¡æ¥å£
 */
export interface ILLMService {
  /**
   * å‘é€æ¶ˆæ¯ï¼ˆä¼ ç»Ÿæ ¼å¼ï¼Œè¿”å›åˆå¹¶çš„å­—ç¬¦ä¸²ï¼‰
   * @deprecated å»ºè®®ä½¿ç”¨ sendMessageStructured è·å¾—æ›´å¥½çš„è¯­ä¹‰æ”¯æŒ
   * @throws {RequestConfigError} å½“å‚æ•°æ— æ•ˆæ—¶
   * @throws {APIError} å½“è¯·æ±‚å¤±è´¥æ—¶
   */
  sendMessage(messages: Message[], provider: string): Promise<string>;

  /**
   * å‘é€æ¶ˆæ¯ï¼ˆç»“æ„åŒ–æ ¼å¼ï¼‰
   * @throws {RequestConfigError} å½“å‚æ•°æ— æ•ˆæ—¶
   * @throws {APIError} å½“è¯·æ±‚å¤±è´¥æ—¶
   */
  sendMessageStructured(messages: Message[], provider: string): Promise<LLMResponse>;



  /**
   * å‘é€æµå¼æ¶ˆæ¯ï¼ˆæ”¯æŒç»“æ„åŒ–å’Œä¼ ç»Ÿæ ¼å¼ï¼‰
   * @throws {RequestConfigError} å½“å‚æ•°æ— æ•ˆæ—¶
   * @throws {APIError} å½“è¯·æ±‚å¤±è´¥æ—¶
   */
  sendMessageStream(
    messages: Message[],
    provider: string,
    callbacks: StreamHandlers
  ): Promise<void>;

  /**
   * å‘é€æ”¯æŒå·¥å…·è°ƒç”¨çš„æµå¼æ¶ˆæ¯ï¼ˆğŸ†• æ–°å¢åŠŸèƒ½ï¼‰
   * @throws {RequestConfigError} å½“å‚æ•°æ— æ•ˆæ—¶
   * @throws {APIError} å½“è¯·æ±‚å¤±è´¥æ—¶
   */
  sendMessageStreamWithTools(
    messages: Message[],
    provider: string,
    tools: ToolDefinition[],
    callbacks: StreamHandlers
  ): Promise<void>;

  /**
   * æµ‹è¯•è¿æ¥
   */
  testConnection(provider: string): Promise<void>;

  /**
   * è·å–æ¨¡å‹åˆ—è¡¨ï¼Œä»¥ä¸‹æ‹‰é€‰é¡¹æ ¼å¼è¿”å›
   * @param provider æä¾›å•†æ ‡è¯†
   * @param customConfig è‡ªå®šä¹‰é…ç½®ï¼ˆå¯é€‰ï¼‰
   * @throws {RequestConfigError} å½“å‚æ•°æ— æ•ˆæ—¶
   * @throws {APIError} å½“è¯·æ±‚å¤±è´¥æ—¶
   */
  fetchModelList(provider: string, customConfig?: Partial<ModelConfig>): Promise<ModelOption[]>;
}